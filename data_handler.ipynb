{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSDC Raw Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"./data/raw_data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compounds_screened = pd.read_csv(\"data/raw_data/all_compounds_screened.csv\")\n",
    "all_cellines_screened = pd.read_excel(\"data/raw_data/all_cellines_screened.xlsx\", sheet_name=0)\n",
    "all_experiment = pd.read_excel(\"data/raw_data/GDSC2_drug_dose_cellines_IC50s.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取有测序结果和甲基化数据等数据的细胞系\n",
    "filtered_celline = all_cellines_screened.loc[\n",
    "    (all_cellines_screened['Whole Exome Sequencing (WES)'] == \"Y\") &\n",
    "    (all_cellines_screened['Methylation'] == \"Y\") &\n",
    "    (all_cellines_screened['Gene Expression'] == \"Y\") &\n",
    "    (all_cellines_screened['Copy Number Alterations (CNA)'] == \"Y\") &\n",
    "    (all_cellines_screened['Drug\\nResponse'] == \"Y\")\n",
    "]\n",
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(all_experiment['CELL_LINE_NAME'])\n",
    "b = set(filtered_celline['Sample Name'])\n",
    "print(f\"experiment sheet includes {a.__len__()} unqiue cellines\")\n",
    "print(f\"all_celline sheet includes {b.__len__()} unique cellines\")\n",
    "celline_barcode = list(a.intersection(b))\n",
    "print(f\"two sheets have {celline_barcode.__len__()} overlapping cellines\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDSC Single Celline Multi-omics data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNV data (Mutation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = pd.read_csv('data/raw_data/mutations_all_20230202.csv', low_memory=False)\n",
    "model_list = pd.read_csv('data/raw_data/model_list_20230306.csv', low_memory=False)\n",
    "snv_df.drop(columns='model_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = snv_df.join(model_list[['model_id', 'model_name']].set_index('model_id'), on=\"model_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " important_only = ['cds_disrupted','complex_sub','downstream', 'ess_splice','frameshift','missense','nonsense','silent','splice_region','start_lost','stop_lost','upstream']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'cds_disrupted', 终止密码子突变\n",
    " 'complex_sub', 复合物替换突变\n",
    " 'downstream', 下游\n",
    " 'ess_splice', 外显子剪辑沉默\n",
    " 'frameshift', 移码突变\n",
    " 'inframe', 开放框架内突变\n",
    " 'intronic', 内显子\n",
    " 'missense', 错义突变\n",
    " 'nc_ess_splice', \n",
    " 'nc_variant', \n",
    " 'nonsense', 无义突变\n",
    " 'silent', 沉默突变\n",
    " 'splice_region', 剪辑区域\n",
    " 'start_lost', 启动子丢失\n",
    " 'stop_lost', 终止密码子丢失\n",
    " 'upstream' 上游"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_only = ['cds_disrupted','complex_sub','downstream', 'ess_splice','frameshift','missense','nonsense','silent','splice_region','start_lost','stop_lost','upstream']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = snv_df[snv_df['effect'].isin(important_only)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.pivot_table(data=snv_df, \n",
    "                          index='model_name', \n",
    "                          columns='gene_symbol', \n",
    "                          values='effect',\n",
    "                          aggfunc='count',\n",
    "                          fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methylation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_df = pd.read_csv('data/raw_data/F2_METH_CELL_DATA.txt', sep = '\\t', index_col=0)\n",
    "met_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_df = met_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_lookup = pd.read_excel('data/raw_data/methSampleId_2_cosmicIds.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_lookup['Sentrix_Barcode'] = list(\"_\".join([i,j]) for i, j in zip(met_lookup['Sentrix_ID'].astype(str), met_lookup['Sentrix_Position']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = dict(zip(met_lookup['Sentrix_Barcode'], met_lookup['Sample_Name']))\n",
    "met_df.rename(columns=tb, inplace=True)\n",
    "met_df = met_df.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Number Variation and FPKM file readin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = pd.read_csv(\"./data/raw_data/celline_SNP6_cnv_gistics_20191101/cnv_gistic_20191101.csv\", low_memory=False,\n",
    "                      skiprows=lambda x: x in [0, 2])\n",
    "all_fpkm = pd.read_csv(\"./data/raw_data/cellines_rnaseq_all_20220624/rnaseq_fpkm_20220624.csv\", low_memory=False,\n",
    "                       skiprows=lambda x: x in [0, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm = all_fpkm.drop(columns=['model_name'])\n",
    "all_fpkm.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_fpkm.set_index('celline_barcode', inplace=True)\n",
    "all_fpkm = all_fpkm.T\n",
    "all_fpkm.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = all_cna.drop(columns=['model_name'])\n",
    "all_cna.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_cna.set_index('celline_barcode', inplace=True)\n",
    "all_cna = all_cna.T\n",
    "all_cna.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(all_fpkm.index).intersection(celline_barcode)\n",
    "s2 = set(all_cna.index).intersection(celline_barcode)\n",
    "celline_barcode = list(s1.intersection(s2))\n",
    "print(f\"Two datasets have {len(celline_barcode)} common cellines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = list(set(cna_df.columns).intersection(fpkm_df.columns))\n",
    "print(f\"Two datasets have {len(common_genes)} genes(features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm.loc[celline_barcode].to_csv(\"./data/processed_data/fpkm.csv\", sep='\\t')\n",
    "all_cna.loc[celline_barcode].to_csv(\"./data/processed_data/cna.csv\", sep='\\t')\n",
    "all_fpkm = all_fpkm.loc[celline_barcode]\n",
    "all_cna = all_cna.loc[celline_barcode]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDSC Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_info: https://www.cancerrxgene.org/downloads/drug_data\n",
    "drug_df = pd.read_csv('./data/raw_data/drug_info.csv', sep=',')\n",
    "drug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubchem_id exclude non-numeric rows\n",
    "import re\n",
    "nonnumber = re.compile(r'\\D+')\n",
    "pubchem_id = list(set(drug_df['pubchem']))\n",
    "pubchem_id = [i.split(',')[0] if \",\" in i else i for i in pubchem_id]\n",
    "pubchem_id = [i for i in pubchem_id if re.findall(pattern=nonnumber, string=i).__len__()==0]\n",
    "drug_df = drug_df[drug_df['pubchem'].isin(pubchem_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.join(drug_df.set_index('drug_name'), on='DRUG_NAME', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['CELL_LINE_NAME'].isin(celline_barcode)]\n",
    "all_experiment.reset_index(inplace = True)\n",
    "all_experiment.drop(columns = \"index\", inplace = True)\n",
    "all_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.to_csv(\"./data/processed_data/expriment.csv\", sep=\"\\t\", index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response and Pubchem ID troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "df = pcp.get_properties(properties=['canonical_smiles'], identifier=list(all_experiment['pubchem']),\n",
    "                        namespace='cid', )\n",
    "df = pd.DataFrame(df)\n",
    "df[['CID']]=df[['CID']].astype(str)\n",
    "df.to_csv(\"./data/processed_data/pubchem_id-SMILES.csv\", sep='\\t')\n",
    "lookup_table_cid_smiles = dict(zip(df['CID'], df['CanonicalSMILES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['PUBCHEM_ID'].isin(pubchem_id)]\n",
    "all_experiment['SMILES']=[lookup_table_cid_smiles[i] for i in all_experiment['PUBCHEM_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_barcode = [f\"{i[0]}_{i[1]}\" for i in zip(all_experiment['CELL_LINE_NAME'], all_experiment['PUBCHEM_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response['sample_barcode'] = sample_barcode\n",
    "response['LN_IC50'] = all_experiment['LN_IC50']\n",
    "response.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exclude outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "ln_ic50 = all_experiment['LN_IC50'].values\n",
    "df = pd.DataFrame(ln_ic50)\n",
    "\n",
    "lower, median, upper = df.quantile([0.15,0.5,0.85]).values\n",
    "IQR = upper - lower\n",
    "lower_limit = lower - 1.5*IQR\n",
    "upper_limit = upper + 1.5*IQR\n",
    "\n",
    "all_experiment.loc[(all_experiment['LN_IC50'] < upper_limit.data) &\n",
    "                   (all_experiment['LN_IC50'] > lower_limit.data)]\n",
    "\n",
    "all_experiment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.to_csv('./data/processed_data/response.csv', sep='\\t', index=None)\n",
    "all_experiment.to_csv('./data/processed_data/expriment.csv', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Feature Extraction using beta-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import realpath\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import BondType\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "SMILE_CHARSET = '[\"C\", \"B\", \"F\", \"I\", \"H\", \"O\", \"N\", \"S\", \"P\", \"Cl\", \"Br\"]'\n",
    "\n",
    "bond_mapping = {\"SINGLE\": 0, \"DOUBLE\": 1, \"TRIPLE\": 2, \"AROMATIC\": 3}\n",
    "bond_mapping.update(\n",
    "    {0: BondType.SINGLE, 1: BondType.DOUBLE, 2: BondType.TRIPLE, 3: BondType.AROMATIC}\n",
    ")\n",
    "SMILE_CHARSET = ast.literal_eval(SMILE_CHARSET)\n",
    "\n",
    "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
    "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
    "atom_mapping = dict(SMILE_to_index)\n",
    "atom_mapping.update(index_to_SMILE)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "VAE_LR = 5e-4\n",
    "NUM_ATOMS = 120  # Maximum number of atoms\n",
    "\n",
    "ATOM_DIM = len(SMILE_CHARSET)  # Number of atom types\n",
    "BOND_DIM = 4 + 1  # Number of bond types\n",
    "LATENT_DIM = 435  # Size of the latent space\n",
    "\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    # Converts SMILES to molecule object\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Initialize adjacency and feature tensor\n",
    "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
    "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
    "\n",
    "    # loop over each atom in molecule\n",
    "    # Ignore Pt Atom\n",
    "    for atom in molecule.GetAtoms():\n",
    "        if(atom.GetSymbol() == \"Pt\"):\n",
    "            continue\n",
    "        i = atom.GetIdx()\n",
    "        atom_type = atom_mapping[atom.GetSymbol()]\n",
    "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
    "        # loop over one-hop neighbors\n",
    "        for neighbor in atom.GetNeighbors():\n",
    "            j = neighbor.GetIdx()\n",
    "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
    "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
    "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
    "\n",
    "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
    "    # Notice: channels-first\n",
    "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
    "\n",
    "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
    "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
    "\n",
    "    return adjacency, features\n",
    "\n",
    "\n",
    "def graph_to_molecule(graph):\n",
    "    # Unpack graph\n",
    "    adjacency, features = graph\n",
    "\n",
    "    # RWMol is a molecule object intended to be edited\n",
    "    molecule = Chem.RWMol()\n",
    "\n",
    "    # Remove \"no atoms\" & atoms with no bonds\n",
    "    keep_idx = np.where(\n",
    "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
    "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
    "    )[0]\n",
    "    features = features[keep_idx]\n",
    "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
    "\n",
    "    # Add atoms to molecule\n",
    "    for atom_type_idx in np.argmax(features, axis=1):\n",
    "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
    "        _ = molecule.AddAtom(atom)\n",
    "\n",
    "    # Add bonds between atoms in molecule; based on the upper triangles\n",
    "    # of the [symmetric] adjacency tensor\n",
    "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
    "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
    "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
    "            continue\n",
    "        bond_type = bond_mapping[bond_ij]\n",
    "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
    "\n",
    "    # Sanitize the molecule; for more information on sanitization, see\n",
    "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "    # Let's be strict. If sanitization fails, return None\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        return None\n",
    "\n",
    "    return molecule\n",
    "\n",
    "\n",
    "# 注：min-Max归一化需要在分割完训练集和测试集和Validation set之后再进行\n",
    "\n",
    "# Cached_data\n",
    "cached_data = {}\n",
    "\n",
    "# Path Define\n",
    "cna_path = realpath(\"data/processed_data/cna.csv\")\n",
    "experiment_path = realpath(\"data/processed_data/experiment.csv\")\n",
    "fpkm_path = realpath(\"data/processed_data/fpkm.csv\")\n",
    "SMILES_path = realpath(\"data/processed_data/pubchem_id-SMILES.csv\")\n",
    "\n",
    "drug_AdjacencyTensor = []\n",
    "drug_FeatureTensor = []\n",
    "\n",
    "df = pd.read_csv(SMILES_path, sep='\\t')\n",
    "for i in df[\"CanonicalSMILES\"]:\n",
    "    _ad, _fe = smiles_to_graph(i)\n",
    "    drug_AdjacencyTensor.append(_ad)\n",
    "    drug_FeatureTensor.append(_fe)\n",
    "\n",
    "drug_AdjacencyTensor = np.array(drug_AdjacencyTensor)\n",
    "drug_FeatureTensor = np.array(drug_FeatureTensor)\n",
    "\n",
    "vae = load_model(\"utils/drug-molecule-generation-with-VAE\",\n",
    "               compile=False)\n",
    "\n",
    "z_mean, _ = vae.encoder.predict([drug_AdjacencyTensor[:1000], drug_FeatureTensor[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CID'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df = pd.DataFrame(data = z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df.head(5) # 435-dim vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNA 和 Gene-Expression dimension reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNA and FPKM data integration using SNF**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNFtool: https://doi.org/10.1038/nmeth.2810\n",
    "\n",
    "R code is in current folder/SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!R CMD BATCH ./SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv(\"data/processed_data/simlilarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celline_feature = {}\n",
    "for i, celline in enumerate(similarity_df.columns):\n",
    "    celline_feature[celline] = np.array(similarity_df.iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in response['sample_barcode']:\n",
    "    celline_name, pubchem_id = i.split('_')\n",
    "    celline_feature_array = celline_feature[celline_name]\n",
    "    drug_feature_array = drug_feature_df.loc[int(pubchem_id)]\n",
    "    combined_feature = np.hstack([celline_feature_array, drug_feature_array])\n",
    "    s.append(combined_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(s).shape # 866+435=1301-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/processed_data/all_feature\", np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "#labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras import Model\n",
    "from keras.metrics import Accuracy, AUC\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "# labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "y = []\n",
    "for i in labels:\n",
    "    if (i[0]<=0.67):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "labels = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOFA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = Dataset()\n",
    "procssed_data = _data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = procssed_data['omics_data']['gene_expression']\n",
    "cnv = procssed_data['omics_data']['cnv']\n",
    "response = procssed_data['response']\n",
    "experiment = procssed_data['experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_experiment = experiment[['SAMPLE_BARCODE', 'CELL_LINE_NAME', 'DRUG_NAME', 'pubchem', 'SMILES', 'AUC', 'Z_SCORE', 'LN_IC50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset with columns # The input needs to be a data.frame with columns [\"sample\",\"feature\",\"view\",\"group\",\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_stakced = gene_expression.stack()\n",
    "cnv_stacked = cnv.stack()\n",
    "prepared_df = pd.DataFrame([[cll, symbol, 'gene_expression', '*', gene_expression_stakced[i]] for i, (cll, symbol) in enumerate(list(gene_expression_stakced.index))]+\n",
    "                           [[cll, symbol, 'cnv', '*', cnv_stacked[i]] for i, (cll, symbol) in enumerate(list(cnv_stacked.index))],\n",
    "                           columns=[\"sample\",\"feature\",\"view\",\"group\",\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.drop_duplicates([\"sample\",\"feature\",\"view\",\"group\"], keep = \"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofapy2.run.entry_point import entry_point\n",
    "###########################\n",
    "## Initialise MOFA model ##\n",
    "###########################\n",
    "\n",
    "\n",
    "## (1) initialise the entry point\n",
    "ent = entry_point()\n",
    "## (2) Set data options\n",
    "# - scale_views: if views have very different ranges, one can to scale each view to unit variance\n",
    "ent.set_data_options(\n",
    "\tscale_views = False\n",
    ")\n",
    "\n",
    "# (3) Set data using the data frame format\n",
    "ent.set_data_df(prepared_df)\n",
    "\n",
    "# using default values\n",
    "ent.set_model_options()\n",
    "\n",
    "# using personalised values\n",
    "ent.set_model_options(\n",
    "\tfactors = 10, \n",
    "\tspikeslab_weights = True, \n",
    "\tard_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Set training options ##\n",
    "# - iter: number of iterations\n",
    "# - convergence_mode: \"fast\", \"medium\", \"slow\". Fast mode is usually good enough.\n",
    "# - dropR2: minimum variance explained criteria to drop factors while training. Default is None, inactive factors are not dropped during training\n",
    "# - gpu_mode: use GPU mode? this functionality needs cupy installed and a functional GPU, see https://biofam.github.io/MOFA2/gpu_training.html\n",
    "# - seed: random seed\n",
    "\n",
    "# using default values\n",
    "ent.set_train_options()\n",
    "\n",
    "# using personalised values\n",
    "ent.set_train_options(\n",
    "\titer = 100, \n",
    "\tconvergence_mode = \"fast\", \n",
    "\tdropR2 = None, \n",
    "\tgpu_mode = False, \n",
    "\tseed = 42\n",
    ")\n",
    "\n",
    "####################################\n",
    "## Build and train the MOFA model ##\n",
    "####################################\n",
    "\n",
    "# Build the model \n",
    "ent.build()\n",
    "\n",
    "# Run the model\n",
    "ent.run()\n",
    "\n",
    "####################\n",
    "## Save the model ##\n",
    "####################\n",
    "\n",
    "outfile = \"./test.hdf5\"\n",
    "\n",
    "# - save_data: logical indicating whether to save the training data in the hdf5 file.\n",
    "# this is useful for some downstream analysis in R, but it can take a lot of disk space.\n",
    "ent.save(outfile, save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "## Downstream analysis ##\n",
    "#########################\n",
    "\n",
    "# Check the mofax package for the downstream analysis in Python: https://github.com/bioFAM/mofax\n",
    "# Check the MOFA2 R package for the downstream analysis in R: https://www.bioconductor.org/packages/release/bioc/html/MOFA2.html\n",
    "# All tutorials: https://biofam.github.io/MOFA2/tutorials.html\n",
    "\n",
    "# Extract factor values (a list with one matrix per sample group)\n",
    "factors = ent.model.nodes[\"Z\"].getExpectation()\n",
    "\n",
    "# Extract weights  (a list with one matrix per view)\n",
    "weights = ent.model.nodes[\"W\"].getExpectation()\n",
    "\n",
    "# Extract variance explained values\n",
    "r2 = ent.model.calculate_variance_explained()\n",
    "\n",
    "# Interact directly with the hdf5 file\n",
    "import h5py\n",
    "f = h5py.File(outfile, 'r')\n",
    "f.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data=weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract factors\n",
    "# f[\"expectations\"][\"Z\"][\"*\"].value\n",
    "\n",
    "# Extract weights\n",
    "#f[\"expectations\"][\"W\"][\"gene_expression\"].value\n",
    "#f[\"expectations\"][\"W\"][\"cnv\"].value\n",
    "\n",
    "# Extract variance explained estimates\n",
    "print(f[\"variance_explained\"][\"r2_per_factor\"])\n",
    "print(f[\"variance_explained\"][\"r2_total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/processed_data/simlilarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x = selected_experiment['LN_IC50'], bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTRP Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.data.curves_post_qc.txt\", sep='\\t')\n",
    "meta_celline = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_cell_line.txt\", sep=\"\\t\")\n",
    "meta_experiment = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_experiment.txt\", sep='\\t')\n",
    "meta_compound = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_compound.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_celline = meta_celline[['master_ccl_id', 'ccl_name']]\n",
    "meta_compound = meta_compound[['master_cpd_id', 'cpd_name', 'cpd_smiles']]\n",
    "meta_experiment = meta_experiment[['experiment_id','master_ccl_id']]\n",
    "experiment = experiment[['experiment_id', 'area_under_curve', 'master_cpd_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = experiment.join(meta_experiment.set_index('experiment_id'), on='experiment_id',how='inner')\n",
    "experiment = experiment.join(meta_compound.set_index('master_cpd_id'), on='master_cpd_id',how='inner')\n",
    "experiment = experiment.join(meta_celline.set_index('master_ccl_id'), on='master_ccl_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = experiment[['experiment_id', 'master_cpd_id', 'cpd_name', 'cpd_smiles',\n",
    "                         'master_ccl_id', 'ccl_name', 'area_under_curve']] # reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Copy Number Abberation Data...\n",
      "Loading Copy Number Abberation Data Done\n",
      "Loading Gene Expression Data...\n",
      "Loading Gene Expression Data Done\n",
      "Begin loading drug data...\n",
      "After filtering, GDSC has tested 398 drugs \n",
      " CTRP has tested 470 drugs\n",
      "After combining, unique cid number is 749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunzehui/miniconda3/envs/tf/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:6300: RuntimeWarning: overflow encountered in _ncf_cdf\n",
      "  return _boost._ncf_cdf(x, dfn, dfd, nc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug data loaded\n",
      "Loading GDSC Experiment Data...\n",
      "Loading Experiment Data Done\n",
      "Index(['DATASET', 'CELL_LINE_NAME', 'DRUG_NAME', 'LN_IC50', 'AUC'], dtype='object')\n",
      "Begin Preprocessing Experiment!\n",
      "Select Overlapping Cellines...\n",
      "Select Overlapping Cellines with available PubChem CIDs...\n",
      "Create Unique Sample Barcode...\n",
      "Exclude response value...\n",
      "Experiment Done!\n"
     ]
    }
   ],
   "source": [
    "from model.data import Dataset\n",
    "from config_path import *\n",
    "\n",
    "ds = Dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10936898362776656"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ds.processed_experiment[ds.processed_experiment['AUC']<0.7].__len__() / len(ds.processed_experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074ed60ff9a97295a85c7cce8cae3388aa83a28770d726c7b567134e875ed814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
