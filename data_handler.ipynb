{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSDC Raw Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"./data/raw_data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compounds_screened = pd.read_csv(\"./data/raw_data/all_compounds_screened.csv\")\n",
    "all_cellines_screened = pd.read_excel(\"./data/raw_data/all_cellines_screened.xlsx\", sheet_name=0)\n",
    "all_experiment = pd.read_excel(\"./data/raw_data/GDSC2_drug_dose_cellines_IC50s.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取有测序结果和甲基化数据等数据的细胞系\n",
    "filtered_celline = all_cellines_screened.loc[\n",
    "    (all_cellines_screened['Whole Exome Sequencing (WES)'] == \"Y\") &\n",
    "    (all_cellines_screened['Methylation'] == \"Y\") &\n",
    "    (all_cellines_screened['Gene Expression'] == \"Y\") &\n",
    "    (all_cellines_screened['Copy Number Alterations (CNA)'] == \"Y\") &\n",
    "    (all_cellines_screened['Drug\\nResponse'] == \"Y\")\n",
    "]\n",
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(all_experiment['CELL_LINE_NAME'])\n",
    "b = set(filtered_celline['Sample Name'])\n",
    "print(f\"experiment sheet includes {a.__len__()} unqiue cellines\")\n",
    "print(f\"all_celline sheet includes {b.__len__()} unique cellines\")\n",
    "celline_barcode = list(a.intersection(b))\n",
    "print(f\"two sheets have {celline_barcode.__len__()} overlapping cellines\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Celline Multi-omics data Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Number Variation and FPKM file readin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = pd.read_csv(\"./data/raw_data/celline_SNP6_cnv_gistics_20191101/cnv_gistic_20191101.csv\", low_memory=False,\n",
    "                      skiprows=lambda x: x in [0, 2])\n",
    "all_fpkm = pd.read_csv(\"./data/raw_data/cellines_rnaseq_all_20220624/rnaseq_fpkm_20220624.csv\", low_memory=False,\n",
    "                       skiprows=lambda x: x in [0, 2, 3, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm = all_fpkm.drop(columns=['model_name'])\n",
    "all_fpkm.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_fpkm.set_index('celline_barcode', inplace=True)\n",
    "all_fpkm = all_fpkm.T\n",
    "all_fpkm.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = all_cna.drop(columns=['model_name'])\n",
    "all_cna.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_cna.set_index('celline_barcode', inplace=True)\n",
    "all_cna = all_cna.T\n",
    "all_cna.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(all_fpkm.index).intersection(celline_barcode)\n",
    "s2 = set(all_cna.index).intersection(celline_barcode)\n",
    "celline_barcode = list(s1.intersection(s2))\n",
    "print(f\"Two datasets have {len(celline_barcode)} common cellines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = list(set(cna_df.columns).intersection(fpkm_df.columns))\n",
    "print(f\"Two datasets have {len(common_genes)} genes(features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm.loc[celline_barcode].to_csv(\"./data/processed_data/fpkm.csv\", sep='\\t')\n",
    "all_cna.loc[celline_barcode].to_csv(\"./data/processed_data/cna.csv\", sep='\\t')\n",
    "all_fpkm = all_fpkm.loc[celline_barcode]\n",
    "all_cna = all_cna.loc[celline_barcode]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDSC Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_info: https://www.cancerrxgene.org/downloads/drug_data\n",
    "drug_df = pd.read_csv('./data/raw_data/drug_info.csv', sep=',')\n",
    "drug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubchem_id exclude non-numeric rows\n",
    "import re\n",
    "nonnumber = re.compile(r'\\D+')\n",
    "pubchem_id = list(set(drug_df['pubchem']))\n",
    "pubchem_id = [i.split(',')[0] if \",\" in i else i for i in pubchem_id]\n",
    "pubchem_id = [i for i in pubchem_id if re.findall(pattern=nonnumber, string=i).__len__()==0]\n",
    "drug_df = drug_df[drug_df['pubchem'].isin(pubchem_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.join(drug_df.set_index('drug_name'), on='DRUG_NAME', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['CELL_LINE_NAME'].isin(celline_barcode)]\n",
    "all_experiment.reset_index(inplace = True)\n",
    "all_experiment.drop(columns = \"index\", inplace = True)\n",
    "all_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.to_csv(\"./data/processed_data/expriment.csv\", sep=\"\\t\", index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response and Pubchem ID troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "df = pcp.get_properties(properties=['canonical_smiles'], identifier=list(all_experiment['pubchem']),\n",
    "                        namespace='cid', )\n",
    "df = pd.DataFrame(df)\n",
    "df[['CID']]=df[['CID']].astype(str)\n",
    "df.to_csv(\"./data/processed_data/pubchem_id-SMILES.csv\", sep='\\t')\n",
    "lookup_table_cid_smiles = dict(zip(df['CID'], df['CanonicalSMILES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['PUBCHEM_ID'].isin(pubchem_id)]\n",
    "all_experiment['SMILES']=[lookup_table_cid_smiles[i] for i in all_experiment['PUBCHEM_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_barcode = [f\"{i[0]}_{i[1]}\" for i in zip(all_experiment['CELL_LINE_NAME'], all_experiment['PUBCHEM_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response['sample_barcode'] = sample_barcode\n",
    "response['LN_IC50'] = all_experiment['LN_IC50']\n",
    "response.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exclude outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "ln_ic50 = all_experiment['LN_IC50'].values\n",
    "df = pd.DataFrame(ln_ic50)\n",
    "\n",
    "lower, median, upper = df.quantile([0.15,0.5,0.85]).values\n",
    "IQR = upper - lower\n",
    "lower_limit = lower - 1.5*IQR\n",
    "upper_limit = upper + 1.5*IQR\n",
    "\n",
    "all_experiment.loc[(all_experiment['LN_IC50'] < upper_limit.data) &\n",
    "                   (all_experiment['LN_IC50'] > lower_limit.data)]\n",
    "\n",
    "all_experiment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.to_csv('./data/processed_data/response.csv', sep='\\t', index=None)\n",
    "all_experiment.to_csv('./data/processed_data/expriment.csv', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Feature Extraction using beta-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import realpath\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import BondType\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "SMILE_CHARSET = '[\"C\", \"B\", \"F\", \"I\", \"H\", \"O\", \"N\", \"S\", \"P\", \"Cl\", \"Br\"]'\n",
    "\n",
    "bond_mapping = {\"SINGLE\": 0, \"DOUBLE\": 1, \"TRIPLE\": 2, \"AROMATIC\": 3}\n",
    "bond_mapping.update(\n",
    "    {0: BondType.SINGLE, 1: BondType.DOUBLE, 2: BondType.TRIPLE, 3: BondType.AROMATIC}\n",
    ")\n",
    "SMILE_CHARSET = ast.literal_eval(SMILE_CHARSET)\n",
    "\n",
    "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
    "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
    "atom_mapping = dict(SMILE_to_index)\n",
    "atom_mapping.update(index_to_SMILE)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "VAE_LR = 5e-4\n",
    "NUM_ATOMS = 120  # Maximum number of atoms\n",
    "\n",
    "ATOM_DIM = len(SMILE_CHARSET)  # Number of atom types\n",
    "BOND_DIM = 4 + 1  # Number of bond types\n",
    "LATENT_DIM = 435  # Size of the latent space\n",
    "\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    # Converts SMILES to molecule object\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Initialize adjacency and feature tensor\n",
    "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
    "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
    "\n",
    "    # loop over each atom in molecule\n",
    "    # Ignore Pt Atom\n",
    "    for atom in molecule.GetAtoms():\n",
    "        if(atom.GetSymbol() == \"Pt\"):\n",
    "            continue\n",
    "        i = atom.GetIdx()\n",
    "        atom_type = atom_mapping[atom.GetSymbol()]\n",
    "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
    "        # loop over one-hop neighbors\n",
    "        for neighbor in atom.GetNeighbors():\n",
    "            j = neighbor.GetIdx()\n",
    "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
    "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
    "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
    "\n",
    "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
    "    # Notice: channels-first\n",
    "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
    "\n",
    "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
    "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
    "\n",
    "    return adjacency, features\n",
    "\n",
    "\n",
    "def graph_to_molecule(graph):\n",
    "    # Unpack graph\n",
    "    adjacency, features = graph\n",
    "\n",
    "    # RWMol is a molecule object intended to be edited\n",
    "    molecule = Chem.RWMol()\n",
    "\n",
    "    # Remove \"no atoms\" & atoms with no bonds\n",
    "    keep_idx = np.where(\n",
    "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
    "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
    "    )[0]\n",
    "    features = features[keep_idx]\n",
    "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
    "\n",
    "    # Add atoms to molecule\n",
    "    for atom_type_idx in np.argmax(features, axis=1):\n",
    "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
    "        _ = molecule.AddAtom(atom)\n",
    "\n",
    "    # Add bonds between atoms in molecule; based on the upper triangles\n",
    "    # of the [symmetric] adjacency tensor\n",
    "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
    "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
    "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
    "            continue\n",
    "        bond_type = bond_mapping[bond_ij]\n",
    "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
    "\n",
    "    # Sanitize the molecule; for more information on sanitization, see\n",
    "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "    # Let's be strict. If sanitization fails, return None\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        return None\n",
    "\n",
    "    return molecule\n",
    "\n",
    "\n",
    "# 注：min-Max归一化需要在分割完训练集和测试集和Validation set之后再进行\n",
    "\n",
    "# Cached_data\n",
    "cached_data = {}\n",
    "\n",
    "# Path Define\n",
    "cna_path = realpath(\"data/processed_data/cna.csv\")\n",
    "experiment_path = realpath(\"data/processed_data/experiment.csv\")\n",
    "fpkm_path = realpath(\"data/processed_data/fpkm.csv\")\n",
    "SMILES_path = realpath(\"data/processed_data/pubchem_id-SMILES.csv\")\n",
    "\n",
    "drug_AdjacencyTensor = []\n",
    "drug_FeatureTensor = []\n",
    "\n",
    "df = pd.read_csv(SMILES_path, sep='\\t')\n",
    "for i in df[\"CanonicalSMILES\"]:\n",
    "    _ad, _fe = smiles_to_graph(i)\n",
    "    drug_AdjacencyTensor.append(_ad)\n",
    "    drug_FeatureTensor.append(_fe)\n",
    "\n",
    "drug_AdjacencyTensor = np.array(drug_AdjacencyTensor)\n",
    "drug_FeatureTensor = np.array(drug_FeatureTensor)\n",
    "\n",
    "vae = load_model(\"./model/drug-molecule-generation-with-VAE\",\n",
    "               compile=False)\n",
    "\n",
    "z_mean, _ = vae.encoder.predict([drug_AdjacencyTensor[:1000], drug_FeatureTensor[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df = pd.DataFrame(data = z_mean, index=df['CID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df.head(5) # 435-dim vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNA 和 Gene-Expression dimension reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNA and FPKM data integration using SNF**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNFtool: https://doi.org/10.1038/nmeth.2810\n",
    "\n",
    "R code is in current folder/SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!R CMD BATCH ./SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv(\"./data/processed_data/simlilarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.columns = cna_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.head() # 就是细胞的Genomic Profiles的特征向量\n",
    "celline_feature = {}\n",
    "for i, celline in enumerate(similarity_df.columns):\n",
    "    celline_feature[celline] = np.array(similarity_df.iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in response['sample_barcode']:\n",
    "    celline_name, pubchem_id = i.split('_')\n",
    "    celline_feature_array = celline_feature[celline_name]\n",
    "    drug_feature_array = drug_feature_df.loc[int(pubchem_id)]\n",
    "    combined_feature = np.hstack([celline_feature_array, drug_feature_array])\n",
    "    s.append(combined_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(s).shape # 866+435=1301-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/processed_data/all_feature\", np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.squeeze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "#labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in y if i==3].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras import Model\n",
    "from keras.metrics import Accuracy, AUC\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "# labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "y = []\n",
    "for i in labels:\n",
    "    if (i[0]<=0.67):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "labels = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074ed60ff9a97295a85c7cce8cae3388aa83a28770d726c7b567134e875ed814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
