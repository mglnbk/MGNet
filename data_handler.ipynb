{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSDC Raw Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"./data/raw_data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compounds_screened = pd.read_csv(\"data/raw_data/all_compounds_screened.csv\")\n",
    "all_cellines_screened = pd.read_excel(\"data/raw_data/all_cellines_screened.xlsx\", sheet_name=0)\n",
    "all_experiment = pd.read_excel(\"data/raw_data/GDSC2_drug_dose_cellines_IC50s.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取有测序结果和甲基化数据等数据的细胞系\n",
    "filtered_celline = all_cellines_screened.loc[\n",
    "    (all_cellines_screened['Whole Exome Sequencing (WES)'] == \"Y\") &\n",
    "    (all_cellines_screened['Methylation'] == \"Y\") &\n",
    "    (all_cellines_screened['Gene Expression'] == \"Y\") &\n",
    "    (all_cellines_screened['Copy Number Alterations (CNA)'] == \"Y\") &\n",
    "    (all_cellines_screened['Drug\\nResponse'] == \"Y\")\n",
    "]\n",
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_celline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(all_experiment['CELL_LINE_NAME'])\n",
    "b = set(filtered_celline['Sample Name'])\n",
    "print(f\"experiment sheet includes {a.__len__()} unqiue cellines\")\n",
    "print(f\"all_celline sheet includes {b.__len__()} unique cellines\")\n",
    "celline_barcode = list(a.intersection(b))\n",
    "print(f\"two sheets have {celline_barcode.__len__()} overlapping cellines\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDSC Single Celline Multi-omics data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNV data (Mutation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = pd.read_csv('data/raw_data/mutations_all_20230202.csv', low_memory=False)\n",
    "model_list = pd.read_csv('data/raw_data/model_list_20230306.csv', low_memory=False)\n",
    "snv_df.drop(columns='model_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = snv_df.join(model_list[['model_id', 'model_name']].set_index('model_id'), on=\"model_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " important_only = ['cds_disrupted','complex_sub','downstream', 'ess_splice','frameshift','missense','nonsense','silent','splice_region','start_lost','stop_lost','upstream']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'cds_disrupted', 终止密码子突变\n",
    " 'complex_sub', 复合物替换突变\n",
    " 'downstream', 下游\n",
    " 'ess_splice', 外显子剪辑沉默\n",
    " 'frameshift', 移码突变\n",
    " 'inframe', 开放框架内突变\n",
    " 'intronic', 内显子\n",
    " 'missense', 错义突变\n",
    " 'nc_ess_splice', \n",
    " 'nc_variant', \n",
    " 'nonsense', 无义突变\n",
    " 'silent', 沉默突变\n",
    " 'splice_region', 剪辑区域\n",
    " 'start_lost', 启动子丢失\n",
    " 'stop_lost', 终止密码子丢失\n",
    " 'upstream' 上游"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_only = ['cds_disrupted','complex_sub','downstream', 'ess_splice','frameshift','missense','nonsense','silent','splice_region','start_lost','stop_lost','upstream']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_df = snv_df[snv_df['effect'].isin(important_only)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.pivot_table(data=snv_df, \n",
    "                          index='model_name', \n",
    "                          columns='gene_symbol', \n",
    "                          values='effect',\n",
    "                          aggfunc='count',\n",
    "                          fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methylation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_df = pd.read_csv('data/raw_data/F2_METH_CELL_DATA.txt', sep = '\\t', index_col=0)\n",
    "met_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_df = met_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_lookup = pd.read_excel('data/raw_data/methSampleId_2_cosmicIds.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_lookup['Sentrix_Barcode'] = list(\"_\".join([i,j]) for i, j in zip(met_lookup['Sentrix_ID'].astype(str), met_lookup['Sentrix_Position']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = dict(zip(met_lookup['Sentrix_Barcode'], met_lookup['Sample_Name']))\n",
    "met_df.rename(columns=tb, inplace=True)\n",
    "met_df = met_df.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Number Variation and FPKM file readin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = pd.read_csv(\"data/raw_data/celline_SNP6_cnv_gistics_20191101/cnv_abs_copy_number_picnic_20191101.csv\", low_memory=False,\n",
    "                      skiprows=lambda x: x in [0, 2])\n",
    "all_fpkm = pd.read_csv(\"./data/raw_data/cellines_rnaseq_all_20220624/rnaseq_fpkm_20220624.csv\", low_memory=False,\n",
    "                       skiprows=lambda x: x in [0, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(all_cna.drop(columns=['model_name', 'Unnamed: 1']).dropna().values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm = all_fpkm.drop(columns=['model_name'])\n",
    "all_fpkm.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_fpkm.set_index('celline_barcode', inplace=True)\n",
    "all_fpkm = all_fpkm.T\n",
    "all_fpkm.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cna = all_cna.drop(columns=['model_name'])\n",
    "all_cna.rename(columns={\"Unnamed: 1\": \"celline_barcode\"}, inplace=True)\n",
    "all_cna.set_index('celline_barcode', inplace=True)\n",
    "all_cna = all_cna.T\n",
    "all_cna.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(all_fpkm.index).intersection(celline_barcode)\n",
    "s2 = set(all_cna.index).intersection(celline_barcode)\n",
    "celline_barcode = list(s1.intersection(s2))\n",
    "print(f\"Two datasets have {len(celline_barcode)} common cellines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = list(set(cna_df.columns).intersection(fpkm_df.columns))\n",
    "print(f\"Two datasets have {len(common_genes)} genes(features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpkm.loc[celline_barcode].to_csv(\"./data/processed_data/fpkm.csv\", sep='\\t')\n",
    "all_cna.loc[celline_barcode].to_csv(\"./data/processed_data/cna.csv\", sep='\\t')\n",
    "all_fpkm = all_fpkm.loc[celline_barcode]\n",
    "all_cna = all_cna.loc[celline_barcode]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDSC Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_info: https://www.cancerrxgene.org/downloads/drug_data\n",
    "drug_df = pd.read_csv('./data/raw_data/drug_info.csv', sep=',')\n",
    "drug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubchem_id exclude non-numeric rows\n",
    "import re\n",
    "nonnumber = re.compile(r'\\D+')\n",
    "pubchem_id = list(set(drug_df['pubchem']))\n",
    "pubchem_id = [i.split(',')[0] if \",\" in i else i for i in pubchem_id]\n",
    "pubchem_id = [i for i in pubchem_id if re.findall(pattern=nonnumber, string=i).__len__()==0]\n",
    "drug_df = drug_df[drug_df['pubchem'].isin(pubchem_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.join(drug_df.set_index('drug_name'), on='DRUG_NAME', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['CELL_LINE_NAME'].isin(celline_barcode)]\n",
    "all_experiment.reset_index(inplace = True)\n",
    "all_experiment.drop(columns = \"index\", inplace = True)\n",
    "all_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.to_csv(\"./data/processed_data/expriment.csv\", sep=\"\\t\", index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response and Pubchem ID troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "df = pcp.get_properties(properties=['canonical_smiles'], identifier=list(all_experiment['pubchem']),\n",
    "                        namespace='cid', )\n",
    "df = pd.DataFrame(df)\n",
    "df[['CID']]=df[['CID']].astype(str)\n",
    "df.to_csv(\"./data/processed_data/pubchem_id-SMILES.csv\", sep='\\t')\n",
    "lookup_table_cid_smiles = dict(zip(df['CID'], df['CanonicalSMILES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = all_experiment[all_experiment['PUBCHEM_ID'].isin(pubchem_id)]\n",
    "all_experiment['SMILES']=[lookup_table_cid_smiles[i] for i in all_experiment['PUBCHEM_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_barcode = [f\"{i[0]}_{i[1]}\" for i in zip(all_experiment['CELL_LINE_NAME'], all_experiment['PUBCHEM_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response['sample_barcode'] = sample_barcode\n",
    "response['LN_IC50'] = all_experiment['LN_IC50']\n",
    "response.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exclude outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "ln_ic50 = all_experiment['LN_IC50'].values\n",
    "df = pd.DataFrame(ln_ic50)\n",
    "\n",
    "lower, median, upper = df.quantile([0.15,0.5,0.85]).values\n",
    "IQR = upper - lower\n",
    "lower_limit = lower - 1.5*IQR\n",
    "upper_limit = upper + 1.5*IQR\n",
    "\n",
    "all_experiment.loc[(all_experiment['LN_IC50'] < upper_limit.data) &\n",
    "                   (all_experiment['LN_IC50'] > lower_limit.data)]\n",
    "\n",
    "all_experiment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.to_csv('./data/processed_data/response.csv', sep='\\t', index=None)\n",
    "all_experiment.to_csv('./data/processed_data/expriment.csv', sep='\\t', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Feature Extraction using beta-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import realpath\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import BondType\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "SMILE_CHARSET = '[\"C\", \"B\", \"F\", \"I\", \"H\", \"O\", \"N\", \"S\", \"P\", \"Cl\", \"Br\"]'\n",
    "\n",
    "bond_mapping = {\"SINGLE\": 0, \"DOUBLE\": 1, \"TRIPLE\": 2, \"AROMATIC\": 3}\n",
    "bond_mapping.update(\n",
    "    {0: BondType.SINGLE, 1: BondType.DOUBLE, 2: BondType.TRIPLE, 3: BondType.AROMATIC}\n",
    ")\n",
    "SMILE_CHARSET = ast.literal_eval(SMILE_CHARSET)\n",
    "\n",
    "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
    "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
    "atom_mapping = dict(SMILE_to_index)\n",
    "atom_mapping.update(index_to_SMILE)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "VAE_LR = 5e-4\n",
    "NUM_ATOMS = 120  # Maximum number of atoms\n",
    "\n",
    "ATOM_DIM = len(SMILE_CHARSET)  # Number of atom types\n",
    "BOND_DIM = 4 + 1  # Number of bond types\n",
    "LATENT_DIM = 435  # Size of the latent space\n",
    "\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    # Converts SMILES to molecule object\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # Initialize adjacency and feature tensor\n",
    "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
    "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
    "\n",
    "    # loop over each atom in molecule\n",
    "    # Ignore Pt Atom\n",
    "    for atom in molecule.GetAtoms():\n",
    "        if(atom.GetSymbol() == \"Pt\"):\n",
    "            continue\n",
    "        i = atom.GetIdx()\n",
    "        atom_type = atom_mapping[atom.GetSymbol()]\n",
    "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
    "        # loop over one-hop neighbors\n",
    "        for neighbor in atom.GetNeighbors():\n",
    "            j = neighbor.GetIdx()\n",
    "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
    "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
    "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
    "\n",
    "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
    "    # Notice: channels-first\n",
    "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
    "\n",
    "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
    "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
    "\n",
    "    return adjacency, features\n",
    "\n",
    "\n",
    "def graph_to_molecule(graph):\n",
    "    # Unpack graph\n",
    "    adjacency, features = graph\n",
    "\n",
    "    # RWMol is a molecule object intended to be edited\n",
    "    molecule = Chem.RWMol()\n",
    "\n",
    "    # Remove \"no atoms\" & atoms with no bonds\n",
    "    keep_idx = np.where(\n",
    "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
    "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
    "    )[0]\n",
    "    features = features[keep_idx]\n",
    "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
    "\n",
    "    # Add atoms to molecule\n",
    "    for atom_type_idx in np.argmax(features, axis=1):\n",
    "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
    "        _ = molecule.AddAtom(atom)\n",
    "\n",
    "    # Add bonds between atoms in molecule; based on the upper triangles\n",
    "    # of the [symmetric] adjacency tensor\n",
    "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
    "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
    "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
    "            continue\n",
    "        bond_type = bond_mapping[bond_ij]\n",
    "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
    "\n",
    "    # Sanitize the molecule; for more information on sanitization, see\n",
    "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "    # Let's be strict. If sanitization fails, return None\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        return None\n",
    "\n",
    "    return molecule\n",
    "\n",
    "\n",
    "# 注：min-Max归一化需要在分割完训练集和测试集和Validation set之后再进行\n",
    "\n",
    "# Cached_data\n",
    "cached_data = {}\n",
    "\n",
    "# Path Define\n",
    "cna_path = realpath(\"data/processed_data/cna.csv\")\n",
    "experiment_path = realpath(\"data/processed_data/experiment.csv\")\n",
    "fpkm_path = realpath(\"data/processed_data/fpkm.csv\")\n",
    "SMILES_path = realpath(\"data/processed_data/pubchem_id-SMILES.csv\")\n",
    "\n",
    "drug_AdjacencyTensor = []\n",
    "drug_FeatureTensor = []\n",
    "\n",
    "df = pd.read_csv(SMILES_path, sep='\\t')\n",
    "for i in df[\"CanonicalSMILES\"]:\n",
    "    _ad, _fe = smiles_to_graph(i)\n",
    "    drug_AdjacencyTensor.append(_ad)\n",
    "    drug_FeatureTensor.append(_fe)\n",
    "\n",
    "drug_AdjacencyTensor = np.array(drug_AdjacencyTensor)\n",
    "drug_FeatureTensor = np.array(drug_FeatureTensor)\n",
    "\n",
    "vae = load_model(\"utils/drug-molecule-generation-with-VAE\",\n",
    "               compile=False)\n",
    "\n",
    "z_mean, _ = vae.encoder.predict([drug_AdjacencyTensor[:1000], drug_FeatureTensor[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CID'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df = pd.DataFrame(data = z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_feature_df.head(5) # 435-dim vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNA 和 Gene-Expression dimension reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNA and FPKM data integration using SNF**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNFtool: https://doi.org/10.1038/nmeth.2810\n",
    "\n",
    "R code is in current folder/SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!R CMD BATCH ./SNL_integration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv(\"data/processed_data/simlilarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celline_feature = {}\n",
    "for i, celline in enumerate(similarity_df.columns):\n",
    "    celline_feature[celline] = np.array(similarity_df.iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in response['sample_barcode']:\n",
    "    celline_name, pubchem_id = i.split('_')\n",
    "    celline_feature_array = celline_feature[celline_name]\n",
    "    drug_feature_array = drug_feature_df.loc[int(pubchem_id)]\n",
    "    combined_feature = np.hstack([celline_feature_array, drug_feature_array])\n",
    "    s.append(combined_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(s).shape # 866+435=1301-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/processed_data/all_feature\", np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "#labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras import Model\n",
    "from keras.metrics import Accuracy, AUC\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.load('./data/processed_data/all_feature.npy')\n",
    "response = pd.read_csv('./data/processed_data/response.csv', sep='\\t')\n",
    "#features = tf.constant(data)\n",
    "labels = response['LN_IC50'].values\n",
    "scaler = MinMaxScaler()\n",
    "labels = labels.reshape(-1,1)\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "# labels = np.squeeze(1)\n",
    "#labels = tf.constant(labels)\n",
    "# dataset = Dataset.from_tensors((features, labels))\n",
    "\n",
    "y = []\n",
    "for i in labels:\n",
    "    if (i[0]<=0.67):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "labels = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOFA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = Dataset()\n",
    "procssed_data = _data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = procssed_data['omics_data']['gene_expression']\n",
    "cnv = procssed_data['omics_data']['cnv']\n",
    "response = procssed_data['response']\n",
    "experiment = procssed_data['experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_experiment = experiment[['SAMPLE_BARCODE', 'CELL_LINE_NAME', 'DRUG_NAME', 'pubchem', 'SMILES', 'AUC', 'Z_SCORE', 'LN_IC50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset with columns # The input needs to be a data.frame with columns [\"sample\",\"feature\",\"view\",\"group\",\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_stakced = gene_expression.stack()\n",
    "cnv_stacked = cnv.stack()\n",
    "prepared_df = pd.DataFrame([[cll, symbol, 'gene_expression', '*', gene_expression_stakced[i]] for i, (cll, symbol) in enumerate(list(gene_expression_stakced.index))]+\n",
    "                           [[cll, symbol, 'cnv', '*', cnv_stacked[i]] for i, (cll, symbol) in enumerate(list(cnv_stacked.index))],\n",
    "                           columns=[\"sample\",\"feature\",\"view\",\"group\",\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.drop_duplicates([\"sample\",\"feature\",\"view\",\"group\"], keep = \"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofapy2.run.entry_point import entry_point\n",
    "###########################\n",
    "## Initialise MOFA model ##\n",
    "###########################\n",
    "\n",
    "\n",
    "## (1) initialise the entry point\n",
    "ent = entry_point()\n",
    "## (2) Set data options\n",
    "# - scale_views: if views have very different ranges, one can to scale each view to unit variance\n",
    "ent.set_data_options(\n",
    "\tscale_views = False\n",
    ")\n",
    "\n",
    "# (3) Set data using the data frame format\n",
    "ent.set_data_df(prepared_df)\n",
    "\n",
    "# using default values\n",
    "ent.set_model_options()\n",
    "\n",
    "# using personalised values\n",
    "ent.set_model_options(\n",
    "\tfactors = 10, \n",
    "\tspikeslab_weights = True, \n",
    "\tard_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (5) Set training options ##\n",
    "# - iter: number of iterations\n",
    "# - convergence_mode: \"fast\", \"medium\", \"slow\". Fast mode is usually good enough.\n",
    "# - dropR2: minimum variance explained criteria to drop factors while training. Default is None, inactive factors are not dropped during training\n",
    "# - gpu_mode: use GPU mode? this functionality needs cupy installed and a functional GPU, see https://biofam.github.io/MOFA2/gpu_training.html\n",
    "# - seed: random seed\n",
    "\n",
    "# using default values\n",
    "ent.set_train_options()\n",
    "\n",
    "# using personalised values\n",
    "ent.set_train_options(\n",
    "\titer = 100, \n",
    "\tconvergence_mode = \"fast\", \n",
    "\tdropR2 = None, \n",
    "\tgpu_mode = False, \n",
    "\tseed = 42\n",
    ")\n",
    "\n",
    "####################################\n",
    "## Build and train the MOFA model ##\n",
    "####################################\n",
    "\n",
    "# Build the model \n",
    "ent.build()\n",
    "\n",
    "# Run the model\n",
    "ent.run()\n",
    "\n",
    "####################\n",
    "## Save the model ##\n",
    "####################\n",
    "\n",
    "outfile = \"./test.hdf5\"\n",
    "\n",
    "# - save_data: logical indicating whether to save the training data in the hdf5 file.\n",
    "# this is useful for some downstream analysis in R, but it can take a lot of disk space.\n",
    "ent.save(outfile, save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "## Downstream analysis ##\n",
    "#########################\n",
    "\n",
    "# Check the mofax package for the downstream analysis in Python: https://github.com/bioFAM/mofax\n",
    "# Check the MOFA2 R package for the downstream analysis in R: https://www.bioconductor.org/packages/release/bioc/html/MOFA2.html\n",
    "# All tutorials: https://biofam.github.io/MOFA2/tutorials.html\n",
    "\n",
    "# Extract factor values (a list with one matrix per sample group)\n",
    "factors = ent.model.nodes[\"Z\"].getExpectation()\n",
    "\n",
    "# Extract weights  (a list with one matrix per view)\n",
    "weights = ent.model.nodes[\"W\"].getExpectation()\n",
    "\n",
    "# Extract variance explained values\n",
    "r2 = ent.model.calculate_variance_explained()\n",
    "\n",
    "# Interact directly with the hdf5 file\n",
    "import h5py\n",
    "f = h5py.File(outfile, 'r')\n",
    "f.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data=weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract factors\n",
    "# f[\"expectations\"][\"Z\"][\"*\"].value\n",
    "\n",
    "# Extract weights\n",
    "#f[\"expectations\"][\"W\"][\"gene_expression\"].value\n",
    "#f[\"expectations\"][\"W\"][\"cnv\"].value\n",
    "\n",
    "# Extract variance explained estimates\n",
    "print(f[\"variance_explained\"][\"r2_per_factor\"])\n",
    "print(f[\"variance_explained\"][\"r2_total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/processed_data/simlilarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x = selected_experiment['LN_IC50'], bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTRP Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.data.curves_post_qc.txt\", sep='\\t')\n",
    "meta_celline = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_cell_line.txt\", sep=\"\\t\")\n",
    "meta_experiment = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_experiment.txt\", sep='\\t')\n",
    "meta_compound = pd.read_csv(\"data/raw_data/CTRPv2.0/v20.meta.per_compound.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_celline = meta_celline[['master_ccl_id', 'ccl_name']]\n",
    "meta_compound = meta_compound[['master_cpd_id', 'cpd_name', 'cpd_smiles']]\n",
    "meta_experiment = meta_experiment[['experiment_id','master_ccl_id']]\n",
    "experiment = experiment[['experiment_id', 'area_under_curve', 'master_cpd_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = experiment.join(meta_experiment.set_index('experiment_id'), on='experiment_id',how='inner')\n",
    "experiment = experiment.join(meta_compound.set_index('master_cpd_id'), on='master_cpd_id',how='inner')\n",
    "experiment = experiment.join(meta_celline.set_index('master_ccl_id'), on='master_ccl_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = experiment[['experiment_id', 'master_cpd_id', 'cpd_name', 'cpd_smiles',\n",
    "                         'master_ccl_id', 'ccl_name', 'area_under_curve']] # reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data import Dataset\n",
    "from config_path import *\n",
    "\n",
    "ds = Dataset(response='AUC', dataset='CTRP')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看AUC和LN_IC50之间的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = ds.experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['AUC'] = (dat['AUC'] - dat['AUC'].min()) / (dat['AUC'].max() - dat['AUC'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, median, upper = dat[['AUC']].quantile([0.33,0.5,0.66]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower)\n",
    "print(median)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ds.processed_experiment['AUC'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "a = K._to_tensor(np.array([[1,2,3,4,5],[3,4,5,6,7]]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrp_drug_df = pd.read_csv('data/raw_data/CTRPv2.0/v20.meta.per_compound.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrp_drug_df['cpd_smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from config_path import *\n",
    "\n",
    "def smiles2canonical(smiles):\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/{smiles}/property/CanonicalSMILES/JSON\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        d = json.loads(response.content)\n",
    "        print(d)\n",
    "        cid = d['PropertyTable']['Properties'][0].get('CID', None)\n",
    "        smiles = d['PropertyTable']['Properties'][0].get('CanonicalSMILES', None)\n",
    "        return (cid, smiles)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_smiles2canonical():\n",
    "    ctrp_drug_df = pd.read_csv(CTRP_DRUG_PATH, sep='\\t').astype(str)\n",
    "    smiles_list = []\n",
    "    cid_list = []\n",
    "    df = pd.DataFrame()\n",
    "    for idx, (name, smiles) in enumerate(list(zip(ctrp_drug_df['cpd_name'], ctrp_drug_df['cpd_smiles']))):\n",
    "        r = smiles2canonical(smiles)\n",
    "        if r is not None: \n",
    "            print(f\"Drug has corresponding canonical smiles and cid\")\n",
    "            smiles_list.append(r[1])\n",
    "            cid_list.append(r[0])\n",
    "        else:\n",
    "            print(f\"Drug has no corresponding Canonical SMILES.\")\n",
    "            smiles_list.append(None)\n",
    "            cid_list.append(None)\n",
    "    df['CanonicalSMILES'] = smiles_list\n",
    "    df.index = ctrp_drug_df['cpd_name']\n",
    "    df['CID'] = [str(i) for i in cid_list]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/raw_data/screened_compounds_rel_8.4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data import Dataset\n",
    "\n",
    "ctrp_ds = Dataset(dataset='CTRP')\n",
    "gdsc_ds = Dataset(dataset=\"GDSC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model.data import Dataset\n",
    "\n",
    "gdsc_ds = Dataset(feature_contained=['cnv', 'gene_expression', 'mutation', 'methylation'], dataset='GDSC')\n",
    "ctrp_ds = Dataset(feature_contained=['cnv', 'gene_expression', 'mutation', 'methylation'], dataset='CTRP')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Hold-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug data loaded\n",
      "Loading CTRP Experiment Data...\n",
      "Loading Experiment Data Done\n",
      "Begin Preprocessing Experiment!\n",
      "Select Overlapping Cellines...\n",
      "Index(['DRUG_NAME', 'SMILES', 'CELL_LINE_NAME', 'AUC', 'DATASET'], dtype='object')\n",
      "Select Overlapping Cellines with available PubChem CIDs...\n",
      "Create Unique Sample Barcode...\n",
      "Exclude response value...\n",
      "Experiment Done!\n",
      "Preparing Omics data...\n",
      "Omics data Done!\n",
      "Save the dataset into hdf5 data format...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 11:03:18.488301: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "580/580 [==============================] - 258s 437ms/step - loss: 0.5186 - precision: 0.5598 - recall: 0.7604 - auc: 0.8274 - auc_1: 0.6957 - val_loss: 0.4652 - val_precision: 0.6211 - val_recall: 0.8662 - val_auc: 0.8924 - val_auc_1: 0.8014 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "580/580 [==============================] - 257s 443ms/step - loss: 0.4122 - precision: 0.6576 - recall: 0.8218 - auc: 0.8938 - auc_1: 0.8038 - val_loss: 0.4978 - val_precision: 0.5928 - val_recall: 0.9315 - val_auc: 0.9162 - val_auc_1: 0.8474 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "580/580 [==============================] - 278s 479ms/step - loss: 0.3914 - precision: 0.6743 - recall: 0.8304 - auc: 0.9048 - auc_1: 0.8208 - val_loss: 0.3758 - val_precision: 0.6895 - val_recall: 0.8628 - val_auc: 0.9198 - val_auc_1: 0.8512 - lr: 0.0010\n",
      "72/72 [==============================] - 26s 354ms/step - loss: 0.3699 - precision: 0.7020 - recall: 0.8545 - auc: 0.9193 - auc_1: 0.8535\n",
      "[0.3698960542678833, 0.7020202279090881, 0.8545082211494446, 0.9193385243415833, 0.8535463213920593]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import datetime\n",
    "from model.nn import multichannel_network\n",
    "from model.data import Dataset, DataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Setting: \n",
    "## choose from ['methylation', 'gene_expression', 'cnv', 'mutation']\n",
    "FEATURE = ['gene_expression', 'cnv', 'methylation', 'mutation']\n",
    "ds = Dataset(\n",
    "    feature_contained=FEATURE, \n",
    "    dataset='CTRP', \n",
    "    set_label=True, \n",
    "    response='AUC', \n",
    "    threshold=.58)\n",
    "# CTRP, \"AUC\", 0.58, 0.001\n",
    "# GDSC, \"AUC\", .88, 0.001\n",
    "# model parameters settings\n",
    "lr_rate = 0.001\n",
    "dropout_rate = .5\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "\n",
    "# Split train, test and validation set for training and testing, build generators\n",
    "partition = ds.split(validation=True)\n",
    "train = partition['train']\n",
    "test = partition['test']\n",
    "validation = partition['validation']\n",
    "train_generator = DataGenerator(sample_barcode=train, **ds.get_config(), batch_size=batch_size)\n",
    "validation_generator = DataGenerator(sample_barcode=validation, **ds.get_config(), batch_size=batch_size)\n",
    "test_generator = DataGenerator(sample_barcode=test, **ds.get_config(), batch_size=batch_size)\n",
    "\n",
    "# Training parameters\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                 classes=np.unique([ds.labels[x] for x in train]),\n",
    "                                                 y=[ds.labels[x] for x in train])\n",
    "weights_dict = {i:w for i,w in enumerate(class_weights)}\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "def scheduler(epoch, lr):\n",
    "    if(epoch % 5 ==0 and epoch !=0):\n",
    "        return lr*0.1\n",
    "    else:\n",
    "        return lr\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=5, min_lr=0.001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "# model building\n",
    "model = multichannel_network(\n",
    "    dataset=ds,\n",
    "    train_sample_barcode=train,\n",
    "    dropout=dropout_rate\n",
    "    )\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_rate),\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=\n",
    "              [\n",
    "                Precision(name=\"precision\"),\n",
    "                Recall(name=\"recall\"),\n",
    "                AUC(curve='ROC'),\n",
    "                AUC(curve='PR')\n",
    "              ]\n",
    "            )\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator, \n",
    "    callbacks=[reduce_lr, early_stop],\n",
    "    class_weight=weights_dict\n",
    "                    )\n",
    "\n",
    "scores = model.evaluate(x=test_generator) \n",
    "print(list(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48955"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.response.__len__()\n",
    "ds.processed_experiment.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 38s 498ms/step\n"
     ]
    }
   ],
   "source": [
    "_predict = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMPLE_BARCODE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22RV1_16-beta-bromoandrosterone</th>\n",
       "      <td>0.679538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22RV1_1S,3R-RSL-3</th>\n",
       "      <td>0.431256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22RV1_3-Cl-AHPC</th>\n",
       "      <td>0.476491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22RV1_968</th>\n",
       "      <td>0.670626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22RV1_ABT-737</th>\n",
       "      <td>0.604091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAPC_veliparib</th>\n",
       "      <td>0.696278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAPC_vincristine</th>\n",
       "      <td>0.548260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAPC_vorapaxar</th>\n",
       "      <td>0.692930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAPC_vorinostat</th>\n",
       "      <td>0.625924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAPC_zebularine</th>\n",
       "      <td>0.664355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40302 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC\n",
       "SAMPLE_BARCODE                           \n",
       "22RV1_16-beta-bromoandrosterone  0.679538\n",
       "22RV1_1S,3R-RSL-3                0.431256\n",
       "22RV1_3-Cl-AHPC                  0.476491\n",
       "22RV1_968                        0.670626\n",
       "22RV1_ABT-737                    0.604091\n",
       "...                                   ...\n",
       "YAPC_veliparib                   0.696278\n",
       "YAPC_vincristine                 0.548260\n",
       "YAPC_vorapaxar                   0.692930\n",
       "YAPC_vorinostat                  0.625924\n",
       "YAPC_zebularine                  0.664355\n",
       "\n",
       "[40302 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.processed_experiment.groupby('SAMPLE_BARCODE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in ds.processed_experiment[ds.target]:\n",
    "                if (i<=ds.threshold):\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38175"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4608/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38175"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.labels.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37162"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38175"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_generator.labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特定药物个案研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = pd.read_csv('data/raw_data/model_list_20230307.csv')[['model_name', 'tissue', 'cancer_type']]\n",
    "colo_ccl = set(model_list[model_list['cancer_type'] == \"Colorectal Carcinoma\"]['model_name'])\n",
    "celline_barcode = set(ds.omics_data['cnv'].index)\n",
    "colo_ccl = colo_ccl.intersection(celline_barcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colo_ccl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_candidate = list(ds.drug_info.all_drugs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "experiment_candidate = itertools.product(colo_ccl, drug_candidate)\n",
    "experiment_candidate = [i for i in experiment_candidate]\n",
    "celline_candidate = [i[0] for i in experiment_candidate]\n",
    "drug_candidate = [i[1] for i in experiment_candidate]\n",
    "feature = {}\n",
    "for i in ds.feature_contained:\n",
    "    if i == \"cnv\":\n",
    "        feature['cnv'] = ds.omics_data['cnv'].loc[celline_candidate].values.astype(np.float32)\n",
    "    elif i == \"gene_expression\":\n",
    "        feature['gene_expression'] = ds.omics_data['gene_expression'].loc[celline_candidate].values.astype(np.float32)\n",
    "    elif i == \"mutation\":\n",
    "        feature['mutation'] = ds.omics_data['mutation'].loc[celline_candidate].values.astype(np.float32)\n",
    "    elif i == \"methylation\":\n",
    "        feature['methylation'] = ds.omics_data['methylation'].loc[celline_candidate].values.astype(np.float32)\n",
    "feature['fingerprint'] = ds.drug_info.drug_feature['fingerprint'].loc[drug_candidate].values.astype(np.float32)\n",
    "feature['rdkit2d'] = ds.drug_info.drug_feature['rdkit2d'].loc[drug_candidate].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for i in range(0, 7920, 32):\n",
    "    x = i\n",
    "    chunks.append({\n",
    "        'cnv': feature['cnv'][x:x+32],\n",
    "        'gene_expression': feature['gene_expression'][x:x+32],\n",
    "        'methylation': feature['methylation'][x:x+32],\n",
    "        'mutation': feature['mutation'][x:x+32],\n",
    "        'fingerprint': feature['fingerprint'][x:x+32],\n",
    "        'rdkit2d': feature['rdkit2d'][x:x+32]\n",
    "    })\n",
    "# last chunk\n",
    "if len(experiment_candidate) % 32 != 0:\n",
    "    last_chunk = {}\n",
    "    leftover = len(experiment_candidate) % 32 \n",
    "    for i,j in feature.items():\n",
    "        last_chunk[i] = np.zeros(shape=(32, j.shape[1]))\n",
    "        last_chunk[i][0:leftover] = j[-leftover::]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for idx, i in enumerate(chunks[:-1]):\n",
    "    result.append(model(i))\n",
    "result.append(model(last_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.concatenate(result, axis=-2)\n",
    "result = result[0:len(experiment_candidate)]\n",
    "df = pd.DataFrame(data=result, columns=['AUC_predicted'])\n",
    "df['DRUG_NAME'] = drug_candidate\n",
    "df['CELL_LINE'] = celline_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exclued = df[~df['DRUG_NAME'].isin(ds.processed_experiment['DRUG_NAME'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment = ds.experiment\n",
    "all_experiment['AUC'] = (all_experiment['AUC'] - all_experiment['AUC'].min())/(all_experiment['AUC'].max()-all_experiment['AUC'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['DRUG_NAME']).intersection(set(all_experiment['DRUG_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment[(all_experiment['CELL_LINE_NAME'].isin(colo_ccl)) &\n",
    "                        (all_experiment['DRUG_NAME'] == 'veliparib')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_exclued.groupby(['DRUG_NAME']).mean().sort_values(by='AUC_predicted', ascending=True).index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074ed60ff9a97295a85c7cce8cae3388aa83a28770d726c7b567134e875ed814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
